{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1ImDDpJmhMCnuX0YG8ZnH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedmahmoodiagents/RAG/blob/main/GraphNodes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai langchain-huggingface --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMhz1kzT4DJi",
        "outputId": "f2f71c65-8f4f-4fbd-a62f-53662357983e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, List, Tuple\n",
        "from langgraph.graph import StateGraph"
      ],
      "metadata": {
        "id": "SAb3PiOxs699"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass"
      ],
      "metadata": {
        "id": "7024lzmz3sXv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HF_TOKEN'] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtfdq49V3uA1",
        "outputId": "fddc1bad-9eb6-44a8-8b61-af7da01e2ced"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROB8dT2_6Hg8",
        "outputId": "c1146c63-12db-4e53-d2b0-1a9079c5fe1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint"
      ],
      "metadata": {
        "id": "V25e3lnY3-0_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def traverse_graph(state):\n",
        "    kg = state[\"knowledge_graph\"]\n",
        "    entities = state[\"entities\"]\n",
        "\n",
        "    facts = []\n",
        "    for e in entities:\n",
        "        for r, o in kg.edges.get(e, []):\n",
        "            facts.append((e, r, o))\n",
        "\n",
        "    state[\"graph_facts\"] = facts\n",
        "    return state"
      ],
      "metadata": {
        "id": "y-9ljtJhtbHZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class KnowledgeGraph:\n",
        "    def __init__(self):\n",
        "        self.nodes = {}   # node_id -> attributes\n",
        "        self.edges = {}   # node_id -> [(relation, target)]\n",
        "\n",
        "    def add_node(self, node_id, **attrs):\n",
        "        self.nodes[node_id] = attrs\n",
        "\n",
        "    def add_edge(self, src, relation, dst):\n",
        "        self.edges.setdefault(src, []).append((relation, dst))\n",
        "\n",
        "    def neighbors(self, node_id):\n",
        "        return self.edges.get(node_id, [])\n"
      ],
      "metadata": {
        "id": "k99PP4Wgtc83"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "kg = KnowledgeGraph()\n",
        "\n",
        "kg.add_node(\"Aspirin\", type=\"drug\")\n",
        "kg.add_node(\"COX-1\", type=\"enzyme\")\n",
        "kg.add_node(\"Prostaglandins\", type=\"chemical\")\n",
        "kg.add_node(\"Inflammation\", type=\"effect\")\n",
        "\n",
        "kg.add_edge(\"Aspirin\", \"inhibits\", \"COX-1\")\n",
        "kg.add_edge(\"COX-1\", \"produces\", \"Prostaglandins\")\n",
        "kg.add_edge(\"Prostaglandins\", \"causes\", \"Inflammation\")"
      ],
      "metadata": {
        "id": "pIMxpUO9te-j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GraphRAGState(TypedDict):\n",
        "    query: str\n",
        "    knowledge_graph: KnowledgeGraph\n",
        "    entities: List[str]\n",
        "    graph_facts: List[Tuple[str, str, str]]\n",
        "    context: str\n",
        "    answer: str\n"
      ],
      "metadata": {
        "id": "qGN7Nol5tg0y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def extract_entities(state: GraphRAGState) -> GraphRAGState:\n",
        "    query = state[\"query\"]\n",
        "    kg = state[\"knowledge_graph\"]\n",
        "\n",
        "    entities = [\n",
        "        e for e in kg.nodes.keys()\n",
        "        if e.lower() in query.lower()\n",
        "    ]\n",
        "\n",
        "    state[\"entities\"] = entities\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "L-mG1QwDtjSl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def traverse_graph(state: GraphRAGState) -> GraphRAGState:\n",
        "    kg = state[\"knowledge_graph\"]\n",
        "    entities = state[\"entities\"]\n",
        "\n",
        "    facts = []\n",
        "\n",
        "    def dfs(node, depth, max_depth=3, visited=None):\n",
        "        if visited is None:\n",
        "            visited = set()\n",
        "        if depth > max_depth or node in visited:\n",
        "            return\n",
        "        visited.add(node)\n",
        "\n",
        "        for rel, nbr in kg.neighbors(node):\n",
        "            facts.append((node, rel, nbr))\n",
        "            dfs(nbr, depth + 1, max_depth, visited)\n",
        "\n",
        "    for e in entities:\n",
        "        dfs(e, 0)\n",
        "\n",
        "    state[\"graph_facts\"] = facts\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "yBCYYp9ZtlbC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_context(state: GraphRAGState) -> GraphRAGState:\n",
        "    lines = [\n",
        "        f\"{s} {r} {o}.\"\n",
        "        for s, r, o in state[\"graph_facts\"]\n",
        "    ]\n",
        "    state[\"context\"] = \"\\n\".join(lines)\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "oXwod8MCWdke"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hI0c8rLx3pX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy LLM (replace with ChatOpenAI / ChatHuggingFace)\n",
        "def answer_llm(state: GraphRAGState) -> GraphRAGState:\n",
        "    prompt = f\"\"\"\n",
        "Use ONLY the following facts to answer the question.\n",
        "\n",
        "Facts:\n",
        "{state['context']}\n",
        "\n",
        "Question:\n",
        "{state['query']}\n",
        "\"\"\"\n",
        "\n",
        "    # Replace this with: llm.invoke(prompt)\n",
        "    state[\"answer\"] = prompt.strip()\n",
        "    return state"
      ],
      "metadata": {
        "id": "wYKpNbHFtXq3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm1 = ChatOpenAI(model='gpt-4o-mini')\n",
        "llm2 = ChatHuggingFace(llm = HuggingFaceEndpoint(repo_id='openai/gpt-oss-20b'))"
      ],
      "metadata": {
        "id": "doX46Uti6g-E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_llm(state: GraphRAGState) -> GraphRAGState:\n",
        "    prompt = f\"\"\"\n",
        "Use ONLY the following facts to answer the question.\n",
        "\n",
        "Facts:\n",
        "{state['context']}\n",
        "\n",
        "Question:\n",
        "{state['query']}\n",
        "\"\"\"\n",
        "\n",
        "    # Replace this with: llm.invoke(prompt)\n",
        "    # state[\"answer\"] = prompt.strip()\n",
        "    state[\"answer\"] = llm2.invoke(prompt)\n",
        "    return state"
      ],
      "metadata": {
        "id": "OKd94skp6e7C"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(GraphRAGState)\n",
        "\n",
        "graph.add_node(\"extract_entities\", extract_entities)\n",
        "graph.add_node(\"traverse_graph\", traverse_graph)\n",
        "graph.add_node(\"build_context\", build_context)\n",
        "graph.add_node(\"answer\", answer_llm)\n",
        "\n",
        "graph.set_entry_point(\"extract_entities\")\n",
        "graph.add_edge(\"extract_entities\", \"traverse_graph\")\n",
        "graph.add_edge(\"traverse_graph\", \"build_context\")\n",
        "graph.add_edge(\"build_context\", \"answer\")\n",
        "\n",
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "L5sLNVmPtUti"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "initial_state: GraphRAGState = {\n",
        "    \"query\": \"How does aspirin reduce inflammation?\",\n",
        "    \"knowledge_graph\": kg,\n",
        "    \"entities\": [],\n",
        "    \"graph_facts\": [],\n",
        "    \"context\": \"\",\n",
        "    \"answer\": \"\"\n",
        "}\n",
        "\n",
        "result = app.invoke(initial_state)\n",
        "\n",
        "print(\"\\n--- GRAPH CONTEXT ---\")\n",
        "print(result[\"context\"])\n",
        "\n",
        "print(\"\\n--- FINAL ANSWER PROMPT ---\")\n",
        "print(result[\"answer\"])\n"
      ],
      "metadata": {
        "id": "mcnLsSx6XPGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be26485-b998-4a66-ca76-c424978ba930"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- GRAPH CONTEXT ---\n",
            "Aspirin inhibits COX-1.\n",
            "COX-1 produces Prostaglandins.\n",
            "Prostaglandins causes Inflammation.\n",
            "\n",
            "--- FINAL ANSWER PROMPT ---\n",
            "content='Aspirin reduces inflammation by inhibiting COX‑1, which in turn lowers the production of prostaglandins. Since prostaglandins cause inflammation, their reduced levels lead to less inflammation.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 126, 'prompt_tokens': 119, 'total_tokens': 245}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_996f667773', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bdeec-5bcf-7b30-9683-6d7ed9b824fa-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 119, 'output_tokens': 126, 'total_tokens': 245}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6oDY71a4tRg4"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}